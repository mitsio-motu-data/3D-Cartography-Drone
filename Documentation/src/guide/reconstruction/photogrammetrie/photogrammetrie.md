# Quelques notions de photogramm√©trie

> Cette section permet simplement d'introduire la notion de [photogramm√©trie](https://fr.wikipedia.org/wiki/Photogramm%C3%A9trie). Le lecteur est encourag√© √† faire des recherches sur ce sujet par lui m√™me. Beaucoup de ressources, plus compl√®tes, existent √† ce sujet.

D'apr√®s une d√©finition d'[IGN France](https://www.ign.fr/institut/kiosque/la-photogrammetrie#:~:text=La%20photogramm%C3%A9trie%20est%20une%20technique,vues%20photographiques%20de%20cet%20objet.), `"La photogramm√©trie est une technique de mesure qui consiste √† d√©terminer la forme, les dimensions et la situation d‚Äôun objet dans l‚Äôespace √† partir de plusieurs prises de vues photographiques de cet objet."`.

Le fonctionnement repose sur la [st√©r√©oscopie](https://fr.wikipedia.org/wiki/St%C3%A9r%C3%A9oscopie), principe qui reprend la vision humaine : obtenir une images en 3 dimensions √† partir de deux images en 2 dimensions.
Pour l'humain, c'est le cerveau qui traite les deux images que nous voyons, une par oeil, pour en obtenir une en 3D.
La st√©reoscopie est une m√©thode ancienne, apparue bien avant l'informatique et m√™me avant la photographie.
Le m√™me principe est utilis√© au cin√©ma avec des projections de films en 3D.

<figure align="center">
    <img src="holmes-stereoscope.jpg" | width=500/>
    <figcaption>St√©reoscope de Holmes</figcaption>
</figure>

Aujourd'hui, il est possible avec un ordinateur de simuler les m√™mes calculs que fait notre cerveau pour que lui aussi puisse obtenir des images 3D √† partir d'images 2D. C'est gr√¢ce √† cela que nous pourrons r√©aliser une reconstruction 3D √† partir d'images 2D. Nous allons pr√©senter les √©tapes principales d'une reconstruction 3D.

> üìñ Nous vous conseillons vivement d'aller lire des sources plus compl√®tes sur le sujet. Voici quelques exemples :
>
> - L'article [Introduction To Feature Detection And Matching](https://medium.com/data-breach/introduction-to-feature-detection-and-matching-65e27179885d)
>   est une bonne base pour comprendre les √©tapes de la d√©tection au matching.
> - Le livre d'Open Drone Map [A Comprehensive Guide To Use OpenDroneMap](https://odmbook.com/)
>   explique toute la file de reconstruction, de mani√®re simple et claire.

## D√©tection de points d'int√©r√™t ou *features*

Pour commencer, il est n√©cessaire de d√©tecter dans chaque image ce que l'on appelle des points d'int√©r√™t ou *features* en anglais. Mais qu'est-ce que c'est ?

Ce sont des points dans l'image dont l'information environnante est suffisament sp√©cifique pour qu'ils soient reconnus dans diff√©rentes images. Plus concr√®tement, il va s'agir par exemple du :

- coin d'un meuble,
- pic d'une montagne,
- angles d'un b√¢timents,
- bord d'un oeil,
- ...

Diff√©rents algorithmes existent pour la d√©tection de points d'int√©r√™t, chacun ayant ses particularit√©s. [Open Drone Map](https://opendronemap.org/), que nous utiliserons pour la reconstruction, utilise [SIFT](https://en.wikipedia.org/wiki/Scale-invariant_feature_transform) par exemple.

<figure align="center">
    <img src="cars.png" | width=600/>
    <figcaption>D√©tection de points d'int√©r√™t - Algorithme d'<a href="https://en.wikipedia.org/wiki/Harris_corner_detector">Harris</a></figcaption>
</figure>

On peut voir dans cette images que les points d√©tect√©s sont en effet plac√©s l√† ou ils pourront √™tre reconnus :

- angles de pare brise,
- angles des camions,
- r√©troviseurs,
- ...

## Description des points

Pour pouvoir identifier chaque point, nous avons besoin d'utiliser un descripteur. Ce dernier va, comme son nom l'indique, d√©crire le point. En langage humain, une descriptions pourrait ressembler √† : "Le point est un angle marron, entour√© d'un peu de rouge et de points verts". L'ordinateur va plut√¥t utiliser des nombres pour caract√©riser toutes les informations du point, lui cr√©ant ainsi une identit√©.

## Association des points entre eux ou *matching*

L'information de profondeur s'obtient en ayant un m√™me point sur plusieurs images dont le point de vue est diff√©rent. Pour faire cela, il faut trouver pour chaque point, toutes les images sur lesquelles il est pr√©sent. Gr√¢ce √† la phase de description, nous allons pouvoir v√©rifier la ressemblance de tous les points de chaque image avec les points des autres images.

 L'image ci-dessous illustre un r√©sultat de matching entre deux images.

<figure align="center">
    <img src="matching.jpg" | width=600/>
    <figcaption>R√©sultat de matching - Image issue de cet <a href="https://medium.com/data-breach/introduction-to-feature-detection-and-matching-65e27179885d">article</a></figcaption>
</figure>

## Meshing

Une fois l'association des points d'int√©r√™t faite, un nuage de points 3D peut √™tre g√©n√©r√©. Ensuite, un algorithme de meshing est appliqu√© pour obtenir une surface. Ce dernier va g√©n√©rer des triangles entres les points du mod√®le 3D, qui constitueront la surface. Le nombre de triangles peut √™tre param√©tr√©. Plus il y en a, meilleure la r√©solution sera (et r√©ciproquement).

| Nuage de points | Mesh |
| :-------------: | :--: |
| ![Bunny point cloud](bunny_pc.jpg) | ![Bunny mesh](bunny_meshed.jpg) |

## Texturing

Cette √©tape permet d'appliquer de la couleur au mod√®le afin de le rendre plus r√©aliste. Comme dit dans [A Comprehensive Guide To Use OpenDroneMap](https://odmbook.com/), √† cette √©tape nous n'avons qu'une `"soupe de polygones"`.

Pour donner de la couleur et texture √† notre mod√®le, on cr√©e un patchwork √† partir des images utilis√©es pour la reconstruction. Puis, on vient "plaquer" ce dernier sur le mesh.

| Texture | Mesh textur√© |
| :-------------: | :--: |
| ![Bunny texture](bunny_texture.jpg) | ![Bunny textured](bunny_textured.jpg) |
